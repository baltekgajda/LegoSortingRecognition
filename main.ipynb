{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr2oN5j7-vnq",
        "colab_type": "code",
        "outputId": "b0363d7f-48e0-4d99-d10c-13fbac7463cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# Install newer version of Pytorch\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl\n",
        "\n",
        "# Cloning ONLY colab-integration branch\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "user = getpass('Github user')\n",
        "password = getpass('Github password')\n",
        "os.environ['GITHUB_AUTH'] = user + ':' + password\n",
        "!git clone -b colab-integration --single-branch \"https://$GITHUB_AUTH@github.com/baltekgajda/LegoSortingRecognition.git\"\n",
        "\n",
        "# Navigate to project folder\n",
        "os.chdir(\"./LegoSortingRecognition\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.1.0 from https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.1.0) (1.16.4)\n",
            "Requirement already satisfied: torchvision==0.3.0 from https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (4.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.16.4)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.1.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.3.0) (0.46)\n",
            "Github user··········\n",
            "Github password··········\n",
            "Cloning into 'LegoSortingRecognition'...\n",
            "remote: Enumerating objects: 186, done.\u001b[K\n",
            "remote: Counting objects: 100% (186/186), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 186 (delta 99), reused 124 (delta 49), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (186/186), 63.89 KiB | 703.00 KiB/s, done.\n",
            "Resolving deltas: 100% (99/99), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzrhtQ49-vns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary libraries\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import json\n",
        "import time\n",
        "\n",
        "from data_loader import load_data\n",
        "from feature_extraction import train_classifier_only, train_classifier_and_last_conv, train_full_net, train_simplified_net\n",
        "from net_test_and_metrics import test_network\n",
        "from svm_classification import train_model_with_svm\n",
        "import VGGFactory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UVRh8J0-vn1",
        "colab_type": "code",
        "outputId": "760ff7f5-6510-414f-9181-d301f0e1f0a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Mount Google Drive to access data\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GLsiVlbIoZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_to_json(variable, results_folder, file_name):\n",
        "  as_json = json.dumps(variable)\n",
        "  f = open(RESULTS_FOLDER + file_name,\"w\")\n",
        "  f.write(as_json)\n",
        "  f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhJnaYtm3tka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_to_csv(variable, results_folder, file_name):\n",
        "    np.savetxt(results_folder + file_name, variable, delimiter=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_axR_-u53l04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_folders():\n",
        "  t = str(time.time())\n",
        "  root = '/content/drive/My Drive/Studia/SNR'\n",
        "  current_execution_dir = '/content/drive/My Drive/Studia/SNR/{}'.format(t)\n",
        "  models_dir = '{}/models/'.format(current_execution_dir)\n",
        "  results_dir = '{}/results/'.format(current_execution_dir)\n",
        "  os.chdir(root)\n",
        "  os.mkdir(current_execution_dir)\n",
        "  os.mkdir(models_dir)\n",
        "  os.mkdir(results_dir)\n",
        "  \n",
        "  return (models_dir, results_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHtXpphgDH5v",
        "colab_type": "code",
        "outputId": "f834caf0-265c-4dd5-dab4-0d0554eb4699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1972
        }
      },
      "source": [
        "models_dir, results_dir = create_folders()\n",
        "NUM_OF_CLASSES = 20\n",
        "NUM_OF_EPOCHS = 50\n",
        "INPUT_SIZE = 224\n",
        "DATA_DIR = '/content/drive/My Drive/Studia/SNR/lego/'\n",
        "MODELS_FOLDER = models_dir\n",
        "RESULTS_FOLDER = results_dir\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "dataloaders_dict = load_data(DATA_DIR, INPUT_SIZE, batch_size=4, num_workers=4)\n",
        "\n",
        "\n",
        "if (torch.cuda.is_available() == False):\n",
        "  raise RuntimeError(\"GPU is not available!\")   \n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "torch.cuda.current_device()\n",
        "\n",
        "\n",
        "model, hist_classifier, test_hist  = train_full_net(dataloaders_dict, MODELS_FOLDER, device, num_of_classes=NUM_OF_CLASSES, num_of_epochs=NUM_OF_EPOCHS)\n",
        "metrics = test_network(model, dataloaders_dict['test'], NUM_OF_CLASSES, device, plot_name='cmc')\n",
        "save_to_json(test_hist, RESULTS_FOLDER, \"test_hist_on_full_net.json\")\n",
        "save_to_json(hist_classifier, RESULTS_FOLDER, \"hist_on_full_net.json\")\n",
        "save_to_json(metrics, RESULTS_FOLDER, \"metrics_on_full_net.json\")\n",
        "\n",
        "m_simplified, hist_classifier, test_hist  = train_simplified_net(model, dataloaders_dict, MODELS_FOLDER, device, num_of_epochs=NUM_OF_EPOCHS)\n",
        "metrics = test_network(m_simplified, dataloaders_dict['test'], NUM_OF_CLASSES, device, plot_name='cmc')\n",
        "save_to_json(test_hist, RESULTS_FOLDER, \"test_hist_simplified.json\")\n",
        "save_to_json(hist_classifier, RESULTS_FOLDER, \"hist_simplified.json\")\n",
        "save_to_json(metrics, RESULTS_FOLDER, \"metrics_simplified.json\")\n",
        "\n",
        "model, hist_classifier, test_hist = train_classifier_only(dataloaders_dict, MODELS_FOLDER, device, num_of_classes=NUM_OF_CLASSES, num_of_epochs=NUM_OF_EPOCHS)\n",
        "metrics = test_network(model, dataloaders_dict['test'], NUM_OF_CLASSES, device, plot_name='cmc')\n",
        "save_to_json(test_hist, RESULTS_FOLDER, \"test_hist_classifier.json\")\n",
        "save_to_json(hist_classifier, RESULTS_FOLDER, \"hist_classifier.json\")\n",
        "save_to_json(metrics, RESULTS_FOLDER, \"metrics_classifier.json\")\n",
        "\n",
        "model, hist_classifier, test_hist  = train_classifier_and_last_conv(dataloaders_dict, MODELS_FOLDER, device, num_of_classes=NUM_OF_CLASSES, num_of_epochs=NUM_OF_EPOCHS)\n",
        "metrics = test_network(model, dataloaders_dict['test'], NUM_OF_CLASSES, device, plot_name='cmc')\n",
        "save_to_json(test_hist, RESULTS_FOLDER, \"test_hist_hist_last_conv.json\")\n",
        "save_to_json(hist_classifier, RESULTS_FOLDER, \"hist_last_conv.json\")\n",
        "save_to_json(metrics, RESULTS_FOLDER, \"metrics_last_conv.json\")\n",
        "\n",
        "svm_model = train_model_with_svm(m_simplified, dataloaders_dict, kernel='l')\n",
        "metrics = test_network(m_simplified, dataloaders_dict['test'], NUM_OF_CLASSES, device, plot_name='cmc', svm_classifier=svm_model)\n",
        "save_to_json(metrics, RESULTS_FOLDER, \"metrics_linear_svm.json\")\n",
        "\n",
        "svm_model = train_model_with_svm(m_simplified, dataloaders_dict, kernel='q')\n",
        "metrics = test_network(m_simplified, dataloaders_dict['test'], NUM_OF_CLASSES, device, plot_name='cmc', svm_classifier=svm_model)\n",
        "save_to_json(metrics, RESULTS_FOLDER, \"metrics_quadratic_svm.json\")\n",
        "\n",
        "svm_model  = train_model_with_svm(m_simplified, dataloaders_dict, kernel='e')\n",
        "metrics = test_network(m_simplified, dataloaders_dict['test'], NUM_OF_CLASSES, device, plot_name='cmc', svm_classifier=svm_model)\n",
        "save_to_json(metrics, RESULTS_FOLDER, \"metrics_exponential_svm.json\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing Datasets and Dataloaders...\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 2.9515 Acc: 0.1298\n",
            "val Loss: 2.7913 Acc: 0.2900\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 2.6880 Acc: 0.3944\n",
            "val Loss: 2.5784 Acc: 0.5054\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 2.5505 Acc: 0.5286\n",
            "val Loss: 2.4801 Acc: 0.6006\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 2.4895 Acc: 0.5883\n",
            "val Loss: 2.4727 Acc: 0.6061\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 2.4709 Acc: 0.6087\n",
            "val Loss: 2.4595 Acc: 0.6190\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 2.4563 Acc: 0.6216\n",
            "val Loss: 2.4779 Acc: 0.5952\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 2.4554 Acc: 0.6216\n",
            "val Loss: 2.4862 Acc: 0.5909\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 2.4308 Acc: 0.6457\n",
            "val Loss: 2.4308 Acc: 0.6472\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 2.3994 Acc: 0.6801\n",
            "val Loss: 2.3978 Acc: 0.6818\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 2.3933 Acc: 0.6853\n",
            "val Loss: 2.4378 Acc: 0.6407\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 2.3680 Acc: 0.7104\n",
            "val Loss: 2.3948 Acc: 0.6818\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 2.3511 Acc: 0.7286\n",
            "val Loss: 2.3544 Acc: 0.7229\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 2.3521 Acc: 0.7258\n",
            "val Loss: 2.3408 Acc: 0.7348\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 2.3422 Acc: 0.7354\n",
            "val Loss: 2.3449 Acc: 0.7338\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 2.3235 Acc: 0.7539\n",
            "val Loss: 2.3342 Acc: 0.7435\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 2.3167 Acc: 0.7601\n",
            "val Loss: 2.2569 Acc: 0.8268\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 2.2457 Acc: 0.8337\n",
            "val Loss: 2.2439 Acc: 0.8377\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 2.2694 Acc: 0.8099\n",
            "val Loss: 2.2588 Acc: 0.8203\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 2.2485 Acc: 0.8306\n",
            "val Loss: 2.2457 Acc: 0.8333\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 2.2446 Acc: 0.8340\n",
            "val Loss: 2.2521 Acc: 0.8268\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 2.2350 Acc: 0.8433\n",
            "val Loss: 2.2369 Acc: 0.8409\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 2.2419 Acc: 0.8368\n",
            "val Loss: 2.2413 Acc: 0.8377\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 2.2393 Acc: 0.8389\n",
            "val Loss: 2.2502 Acc: 0.8301\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 2.2367 Acc: 0.8408\n",
            "val Loss: 2.2343 Acc: 0.8442\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 2.2350 Acc: 0.8430\n",
            "val Loss: 2.2419 Acc: 0.8355\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 2.2300 Acc: 0.8473\n",
            "val Loss: 2.2368 Acc: 0.8420\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 2.2320 Acc: 0.8457\n",
            "val Loss: 2.2335 Acc: 0.8463\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 2.2355 Acc: 0.8417\n",
            "val Loss: 2.2474 Acc: 0.8323\n",
            "Epoch 28/49\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFdxKImt6FTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This probably can be deleted\n",
        "\n",
        "# m_classifier, hist_classifier = train_classifier_only(dataloaders_dict, MODELS_FOLDER, device, num_of_classes=NUM_OF_CLASSES, num_of_epochs=NUM_OF_EPOCHS)\n",
        "# metrics_classifier = test_network(m_classifier, dataloaders_dict['test'], device, plot_name='cmc')\n",
        "# save_to_json(hist_classifier, RESULTS_FOLDER, \"hist_classifier.json\")\n",
        "# save_to_json(metrics_classifier, RESULTS_FOLDER, \"metrics_classifier.json\")\n",
        "\n",
        "# m_last_conv, hist_last_conv = train_classifier_and_last_conv(dataloaders_dict, MODELS_FOLDER, device, num_of_classes=NUM_OF_CLASSES, num_of_epochs=NUM_OF_EPOCHS)\n",
        "# metrics_last_conv = test_network(m_last_conv, dataloaders_dict['test'], device, plot_name='cmc')\n",
        "# save_to_json(hist_last_conv, RESULTS_FOLDER, \"hist_last_conv.json\")\n",
        "# save_to_json(metrics_last_conv, RESULTS_FOLDER, \"metrics_last_conv.json\")\n",
        "\n",
        "# m_on_full_net, hist_on_full_net = train_full_net(dataloaders_dict, MODELS_FOLDER, device, num_of_classes=NUM_OF_CLASSES, num_of_epochs=NUM_OF_EPOCHS)\n",
        "# metrics_on_full_net = test_network(m_on_full_net, dataloaders_dict['test'], device, plot_name='cmc')\n",
        "# save_to_json(hist_on_full_net, RESULTS_FOLDER, \"hist_on_full_net.json\")\n",
        "# save_to_json(metrics_on_full_net, RESULTS_FOLDER, \"metrics_on_full_net.json\")\n",
        "\n",
        "# m_simplified, hist_simplified = train_simplified_net(model_on_full_net, dataloaders_dict, MODELS_FOLDER, device, num_of_classes=NUM_OF_CLASSES, num_of_epochs=NUM_OF_EPOCHS)\n",
        "# metrics_simplified_net = test_network(m_simplified, dataloaders_dict['test'], device, plot_name='cmc')\n",
        "# save_to_json(hist_simplified, RESULTS_FOLDER, \"hist_simplified.json\")\n",
        "# save_to_json(metrics_on_full_net, RESULTS_FOLDER, \"metrics_on_full_net.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_1xG3D6gREF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "shutil.rmtree('./LegoSortingRecognition')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}