{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr2oN5j7-vnq",
        "colab_type": "code",
        "outputId": "08e8781c-0e0e-4bb5-90a2-4e88d098b02c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# Install newer version of Pytorch\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl\n",
        "\n",
        "# Cloning ONLY colab-integration branch\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "user = getpass('Github user')\n",
        "password = getpass('Githyb password')\n",
        "os.environ['GITHUB_AUTH'] = user + ':' + password\n",
        "!git clone -b colab-integration --single-branch \"https://$GITHUB_AUTH@github.com/baltekgajda/LegoSortingRecognition.git\"\n",
        "\n",
        "# Navigate to project folder\n",
        "os.chdir(\"./LegoSortingRecognition\")\n",
        "\n",
        "# Create dir for models and results\n",
        "!mkdir models\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.1.0 from https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.1.0) (1.16.4)\n",
            "Requirement already satisfied: torchvision==0.3.0 from https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.16.4)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.1.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.3.0) (0.46)\n",
            "Github user··········\n",
            "Githyb password··········\n",
            "Cloning into 'LegoSortingRecognition'...\n",
            "remote: Enumerating objects: 111, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 111 (delta 53), reused 78 (delta 28), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (111/111), 38.70 KiB | 12.90 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzrhtQ49-vns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary libraries\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "from google.colab import drive\n",
        "from torchsummary import summary\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from data_loader import load_data\n",
        "from feature_extraction import train_classifier_only, train_classifier_and_last_conv, train_full_net, train_simplified_net\n",
        "from net_test_and_metrics import test_network\n",
        "import VGGFactory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UVRh8J0-vn1",
        "colab_type": "code",
        "outputId": "c80870a1-a8c6-436b-9979-c7ffcfc945f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Mount Google Drive to access data\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHtXpphgDH5v",
        "colab_type": "code",
        "outputId": "6a80153a-bd70-4c5b-e3d7-4c2f2e79b6eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "source": [
        "NUM_OF_CLASSES = 20\n",
        "NUM_OF_EPOCHS = 1\n",
        "INPUT_SIZE = 224\n",
        "DATA_DIR = '/content/drive/My Drive/Studia/SNR/lego/'\n",
        "MODELS_FOLDER = '/content/drive/My Drive/Studia/SNR/models/'\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "dataloaders_dict = load_data(DATA_DIR, INPUT_SIZE, batch_size=32, num_workers=4)\n",
        "\n",
        "\n",
        "if (torch.cuda.is_available() == False):\n",
        "  raise RuntimeError(\"GPU is not available!\")   \n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "torch.cuda.current_device()\n",
        "\n",
        "\n",
        "m_classifier, hist_classifier = train_classifier_only(dataloaders_dict, MODELS_FOLDER, device, num_of_classes=NUM_OF_CLASSES, num_of_epochs=NUM_OF_EPOCHS)\n",
        "# test_network(m_classifier, dataloaders_dict['test'], device, plot_name='cmc')\n",
        "\n",
        "# m_last_conv, hist_last_conv = train_classifier_and_last_conv(dataloaders_dict, MODELS_FOLDER, device, num_of_classes=NUM_OF_CLASSES, num_of_epochs=NUM_OF_EPOCHS)\n",
        "# test_network(m_last_conv, dataloaders_dict['test'], device, plot_name='cmc')\n",
        "\n",
        "# m_on_full_net, hist_on_full_net = train_full_net(dataloaders_dict, MODELS_FOLDER, device, num_of_classes=NUM_OF_CLASSES, num_of_epochs=NUM_OF_EPOCHS)\n",
        "# test_network(m_classm_on_full_netifier, dataloaders_dict['test'], device, plot_name='cmc')\n",
        "\n",
        "# m_simplified, hist_simplified = train_simplified_net(model_on_full_net, dataloaders_dict, MODELS_FOLDER, device, num_of_classes=NUM_OF_CLASSES, num_of_epochs=NUM_OF_EPOCHS)\n",
        "# test_network(m_simplified)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing Datasets and Dataloaders...\n",
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 2.9953 Acc: 0.0569\n",
            "val Loss: 2.9951 Acc: 0.0931\n",
            "\n",
            "Training complete in 0m 41s\n",
            "Best val Acc: 0.093074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-037d269c681e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mm_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_classifier_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODELS_FOLDER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_OF_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_OF_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m# test_network(m_classifier, dataloaders_dict['test'], device, plot_name='cmc')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/LegoSortingRecognition/feature_extraction.py\u001b[0m in \u001b[0;36mtrain_classifier_only\u001b[0;34m(dataloaders_dicts, models_folder, device, num_of_classes, num_of_epochs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_classifier_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_train_model_for_scenario\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"vgg-classifier-only\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/LegoSortingRecognition/feature_extraction.py\u001b[0m in \u001b[0;36m_train_model_for_scenario\u001b[0;34m(scenario_id, model_name, models_folder, dataloaders_dicts, device, num_of_classes, num_of_epochs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_of_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'content/drive/My Drive/Studia/SNR/models/vgg-classifier-only.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_1xG3D6gREF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "shutil.rmtree('./LegoSortingRecognition')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KJBPrjG-vn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num_classes = 20\n",
        "# num_of_epochs = 50\n",
        "# input_size = 224\n",
        "\n",
        "# model = VGGFactory.create_model(1, num_classes)\n",
        "# for name, param in model.named_parameters():\n",
        "#     if param.requires_grad:\n",
        "#         print(name)\n",
        "\n",
        "# print()\n",
        "\n",
        "# simple_model = VGGFactory.simplify_model(model)\n",
        "# for name, param in simple_model.named_parameters():\n",
        "#     if param.requires_grad:\n",
        "#         print(name)\n",
        "\n",
        "# print(\"Initializing Datasets and Dataloaders...\")\n",
        "# dataloaders_dict = load_data(data_dir, input_size, 0.3, 0.1, 0.1)\n",
        "\n",
        "# params_to_update = model.parameters()\n",
        "# print(\"Params to learn:\")\n",
        "# params_to_update = []\n",
        "# for name, param in model.named_parameters():\n",
        "#     if param.requires_grad:\n",
        "#         params_to_update.append(param)\n",
        "#         print(\"\\t\", name)\n",
        "\n",
        "# optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
        "\n",
        "# # Setup the loss fxn\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# # Detect if we have a GPU available\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # Necessary to run script on Windows\n",
        "# torch.cuda.current_device()\n",
        "\n",
        "# # Train and evaluate\n",
        "# model_ft, hist = train_model(model, dataloaders_dict, criterion, optimizer_ft, device, num_epochs=num_of_epochs)\n",
        "\n",
        "# # Save trained model\n",
        "# utils.save_model(model_ft, \"./models\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}